{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b56779a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# \"\"\"\n",
    "# @author: Zongyi Li\n",
    "# This file is the Fourier Neural Operator for 3D problem such as the Navier-Stokes equation discussed in Section 5.3 in the [paper](https://arxiv.org/pdf/2010.08895.pdf),\n",
    "# which takes the 2D spatial + 1D temporal equation directly as a 3D problem\n",
    "# FNO: https://github.com/zongyi-li/fourier_neural_operator\n",
    "# UNO: https://github.com/ashiq24/UNO\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "from scipy import signal\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import operator\n",
    "from functools import reduce\n",
    "from functools import partial\n",
    "\n",
    "from timeit import default_timer\n",
    "import pickle\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "\n",
    "class GaussianNormalizer(object):\n",
    "    def __init__(self, x, eps=0.00001):\n",
    "        super(GaussianNormalizer, self).__init__()\n",
    "\n",
    "        self.mean = torch.mean(x)\n",
    "        self.std = torch.std(x)\n",
    "        self.eps = eps\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = (x - self.mean) / (self.std + self.eps)\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, sample_idx=None):\n",
    "        x = (x * (self.std + self.eps)) + self.mean\n",
    "        return x\n",
    "\n",
    "    def cuda(self):\n",
    "        self.mean = self.mean.to(device)\n",
    "        self.std = self.std.to(device)\n",
    "\n",
    "    def cpu(self):\n",
    "        self.mean = self.mean.cpu()\n",
    "        self.std = self.std.cpu()\n",
    "\n",
    "# normalization, pointwise gaussian\n",
    "\n",
    "\n",
    "class UnitGaussianNormalizer(object):\n",
    "    def __init__(self, x, eps=0.00001):\n",
    "        super(UnitGaussianNormalizer, self).__init__()\n",
    "\n",
    "        # x could be in shape of ntrain*n or ntrain*T*n or ntrain*n*T\n",
    "        self.mean = torch.mean(x, 0)\n",
    "        self.std = torch.std(x, 0)\n",
    "        self.eps = eps\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = (x - self.mean) / (self.std + self.eps)\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, sample_idx=None):\n",
    "        if sample_idx is None:\n",
    "            std = self.std + self.eps  # n\n",
    "            mean = self.mean\n",
    "        else:\n",
    "            if len(self.mean.shape) == len(sample_idx[0].shape):\n",
    "                std = self.std[sample_idx] + self.eps  # batch*n\n",
    "                mean = self.mean[sample_idx]\n",
    "            if len(self.mean.shape) > len(sample_idx[0].shape):\n",
    "                std = self.std[:, sample_idx] + self.eps  # T*batch*n\n",
    "                mean = self.mean[:, sample_idx]\n",
    "\n",
    "        # x is in shape of batch*n or T*batch*n\n",
    "        x = (x * std) + mean\n",
    "        return x\n",
    "\n",
    "    def cuda(self):\n",
    "        self.mean = self.mean.to(device)\n",
    "        self.std = self.std.to(device)\n",
    "\n",
    "    def cpu(self):\n",
    "        self.mean = self.mean.cpu()\n",
    "        self.std = self.std.cpu()\n",
    "\n",
    "# normalization, pointwise gaussian\n",
    "\n",
    "\n",
    "class InputNormalizer(object):\n",
    "    def __init__(self, x, eps=0.00001, nmax=None):\n",
    "        super(InputNormalizer, self).__init__()\n",
    "\n",
    "        # x could be in shape of ntrain*n or ntrain*T*n or ntrain*n*T\n",
    "        if max is not None:\n",
    "            self.mean = torch.mean(x[:nmax], dim=(1, 2, 3))\n",
    "            self.mean = self.mean.mean(dim=0)\n",
    "            self.std = torch.std(x[:nmax], dim=(1, 2, 3))\n",
    "            self.std = self.std.mean(dim=0)\n",
    "        else:\n",
    "            self.mean = torch.mean(x, dim=(1, 2, 3))\n",
    "            self.mean = self.mean.mean(dim=0)\n",
    "            self.std = torch.std(x, dim=(1, 2, 3))\n",
    "            self.std = self.std.mean(dim=0)\n",
    "        self.eps = eps\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = (x - self.mean) / (self.std + self.eps)\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, sample_idx=None):\n",
    "        if sample_idx is None:\n",
    "            std = self.std + self.eps  # n\n",
    "            mean = self.mean\n",
    "        else:\n",
    "            if len(self.mean.shape) == len(sample_idx[0].shape):\n",
    "                std = self.std[sample_idx] + self.eps  # batch*n\n",
    "                mean = self.mean[sample_idx]\n",
    "            if len(self.mean.shape) > len(sample_idx[0].shape):\n",
    "                std = self.std[:, sample_idx] + self.eps  # T*batch*n\n",
    "                mean = self.mean[:, sample_idx]\n",
    "\n",
    "        # x is in shape of batch*n or T*batch*n\n",
    "        x = (x * std) + mean\n",
    "        return x\n",
    "\n",
    "    def cuda(self):\n",
    "        self.mean = self.mean.to(device)\n",
    "        self.std = self.std.to(device)\n",
    "\n",
    "    def cpu(self):\n",
    "        self.mean = self.mean.cpu()\n",
    "        self.std = self.std.cpu()\n",
    "\n",
    "\n",
    "# loss function with rel/abs Lp loss\n",
    "class LpLoss(object):\n",
    "    def __init__(self, d=2, p=2, size_average=True, reduction=True):\n",
    "        super(LpLoss, self).__init__()\n",
    "\n",
    "        # Dimension and Lp-norm type are postive\n",
    "        assert d > 0 and p > 0\n",
    "\n",
    "        self.d = d\n",
    "        self.p = p\n",
    "        self.reduction = reduction\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def abs(self, x, y):\n",
    "        num_examples = x.size()[0]\n",
    "\n",
    "        # Assume uniform mesh\n",
    "        h = 1.0 / (x.size()[1] - 1.0)\n",
    "\n",
    "        all_norms = (h**(self.d / self.p)) *             torch.norm(x.view(num_examples, -1) - y.view(num_examples, -1), self.p, 1)\n",
    "\n",
    "        if self.reduction:\n",
    "            if self.size_average:\n",
    "                return torch.mean(all_norms)\n",
    "            else:\n",
    "                return torch.sum(all_norms)\n",
    "\n",
    "        return all_norms\n",
    "\n",
    "    def rel(self, x, y):\n",
    "        num_examples = x.size()[0]\n",
    "\n",
    "        diff_norms = torch.norm(x.reshape(\n",
    "            num_examples, -1) - y.reshape(num_examples, -1), self.p, 1)\n",
    "        y_norms = torch.norm(y.reshape(num_examples, -1), self.p, 1)\n",
    "\n",
    "        if self.reduction:\n",
    "            if self.size_average:\n",
    "                return torch.mean(diff_norms / y_norms)\n",
    "            else:\n",
    "                return torch.sum(diff_norms / y_norms)\n",
    "\n",
    "        return diff_norms / y_norms\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        return self.rel(x, y)\n",
    "\n",
    "################################################################\n",
    "# Code of UNO3D starts\n",
    "# Pointwise and Fourier Layer\n",
    "################################################################\n",
    "\n",
    "class SpectralConv3d_UNO(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            D1,\n",
    "            D2,\n",
    "            D3,\n",
    "            modes1=None,\n",
    "            modes2=None,\n",
    "            modes3=None):\n",
    "        super(SpectralConv3d_UNO, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        3D Fourier layer. It does FFT, linear transform, and Inverse FFT.\n",
    "        D1, D2, D3 are output dimensions (x,y,t)\n",
    "        modes1,modes2,modes3 = Number of fourier coefficinets to consider along each spectral dimesion\n",
    "        \"\"\"\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.d1 = D1\n",
    "        self.d2 = D2\n",
    "        self.d3 = D3\n",
    "        if modes1 is not None:\n",
    "            # Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
    "            self.modes1 = modes1\n",
    "            self.modes2 = modes2\n",
    "            self.modes3 = modes3\n",
    "        else:\n",
    "            self.modes1 = D1  # Will take the maximum number of possiblel modes for given output dimension\n",
    "            self.modes2 = D2\n",
    "            self.modes3 = D3 // 2 + 1\n",
    "\n",
    "        self.scale = (1 / (2 * in_channels))**(1.0 / 2.0)\n",
    "        self.weights1 = nn.Parameter(\n",
    "            self.scale *\n",
    "            torch.rand(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                self.modes1,\n",
    "                self.modes2,\n",
    "                self.modes3,\n",
    "                dtype=torch.cfloat))\n",
    "        self.weights2 = nn.Parameter(\n",
    "            self.scale *\n",
    "            torch.rand(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                self.modes1,\n",
    "                self.modes2,\n",
    "                self.modes3,\n",
    "                dtype=torch.cfloat))\n",
    "        self.weights3 = nn.Parameter(\n",
    "            self.scale *\n",
    "            torch.rand(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                self.modes1,\n",
    "                self.modes2,\n",
    "                self.modes3,\n",
    "                dtype=torch.cfloat))\n",
    "        self.weights4 = nn.Parameter(\n",
    "            self.scale *\n",
    "            torch.rand(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                self.modes1,\n",
    "                self.modes2,\n",
    "                self.modes3,\n",
    "                dtype=torch.cfloat))\n",
    "\n",
    "    # Complex multiplication\n",
    "    def compl_mul3d(self, input, weights):\n",
    "        # (batch, in_channel, x,y,t ), (in_channel, out_channel, x,y,t) -> (batch, out_channel, x,y,t)\n",
    "        return torch.einsum(\"bixyz,ioxyz->boxyz\", input, weights)\n",
    "\n",
    "    def forward(self, x, D1=None, D2=None, D3=None):\n",
    "        \"\"\"\n",
    "        D1,D2,D3 are the output dimensions (x,y,t)\n",
    "        \"\"\"\n",
    "        if D1 is not None:\n",
    "            self.d1 = D1\n",
    "            self.d2 = D2\n",
    "            self.d3 = D3\n",
    "\n",
    "        batchsize = x.shape[0]\n",
    "        # Compute Fourier coeffcients up to factor of e^(- something constant)\n",
    "        x_ft = torch.fft.rfftn(x, dim=[-3, -2, -1], norm = 'forward')\n",
    "\n",
    "        # Multiply relevant Fourier modes\n",
    "        out_ft = torch.zeros(\n",
    "            batchsize,\n",
    "            self.out_channels,\n",
    "            self.d1,\n",
    "            self.d2,\n",
    "            self.d3 // 2 + 1,\n",
    "            dtype=torch.cfloat,\n",
    "            device=x.device)\n",
    "\n",
    "        out_ft[:, :, :self.modes1, :self.modes2, :self.modes3] = self.compl_mul3d(x_ft[:, :, :self.modes1, :self.modes2, :self.modes3], self.weights1)\n",
    "        out_ft[:, :, -self.modes1:, :self.modes2, :self.modes3] = self.compl_mul3d(x_ft[:, :, -self.modes1:, :self.modes2, :self.modes3], self.weights2)\n",
    "        out_ft[:, :, :self.modes1, -self.modes2:, :self.modes3] = self.compl_mul3d(x_ft[:, :, :self.modes1, -self.modes2:, :self.modes3], self.weights3)\n",
    "        out_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3] = self.compl_mul3d(x_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3], self.weights4)\n",
    "\n",
    "        # Return to physical space\n",
    "        x = torch.fft.irfftn(out_ft, s=(self.d1, self.d2, self.d3) , norm = 'forward')\n",
    "        return x\n",
    "\n",
    "\n",
    "class pointwise_op_3D(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, dim1, dim2, dim3):\n",
    "        super(pointwise_op_3D, self).__init__()\n",
    "        self.conv = nn.Conv3d(int(in_channel), int(out_channel), 1)\n",
    "        self.dim1 = int(dim1)\n",
    "        self.dim2 = int(dim2)\n",
    "        self.dim3 = int(dim3)\n",
    "\n",
    "    def forward(self, x, dim1=None, dim2=None, dim3=None):\n",
    "        \"\"\"\n",
    "        dim1,dim2,dim3 are the output dimensions (x,y,t)\n",
    "        \"\"\"\n",
    "        if dim1 is None:\n",
    "            dim1 = self.dim1\n",
    "            dim2 = self.dim2\n",
    "            dim3 = self.dim3\n",
    "        x_out = self.conv(x)\n",
    "        \n",
    "        ft = torch.fft.rfftn(x_out,dim=[-3,-2,-1])\n",
    "        ft_u = torch.zeros_like(ft)\n",
    "        ft_u[:, :, :(dim1//2), :(dim2//2), :(dim3//2)] = ft[:, :, :(dim1//2), :(dim2//2), :(dim3//2)]\n",
    "        ft_u[:, :, -(dim1//2):, :(dim2//2), :(dim3//2)] = ft[:, :, -(dim1//2):, :(dim2//2), :(dim3//2)]\n",
    "        ft_u[:, :, :(dim1//2), -(dim2//2):, :(dim3//2)] = ft[:, :, :(dim1//2), -(dim2//2):, :(dim3//2)]\n",
    "        ft_u[:, :, -(dim1//2):, -(dim2//2):, :(dim3//2)] = ft[:, :, -(dim1//2):, -(dim2//2):, :(dim3//2)]\n",
    "\n",
    "        x_out = torch.fft.irfftn(ft_u, s=(dim1, dim2, dim3))\n",
    "\n",
    "        \n",
    "        x_out = torch.nn.functional.interpolate(x_out, size=(\n",
    "            dim1, dim2, dim3), mode='trilinear', align_corners=True)\n",
    "        return x_out\n",
    "\n",
    "class OperatorBlock_3D(nn.Module,):\n",
    "    \"\"\"\n",
    "    To turn to normalization set Normalize = True\n",
    "    To have linear operator set Non_Lin = False\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channel, out_channel,res1, res2,res3,modes1,modes2,modes3, Normalize = True, Non_Lin = True):\n",
    "        super(OperatorBlock_3D,self).__init__()\n",
    "        self.conv = SpectralConv3d_UNO(in_channel, out_channel, res1,res2,res3,modes1,modes2,modes3)\n",
    "        self.w = pointwise_op_3D(in_channel, out_channel, res1,res2,res3)\n",
    "        self.normalize = Normalize\n",
    "        self.non_lin = Non_Lin\n",
    "        if Normalize:\n",
    "            self.normalize_layer = torch.nn.InstanceNorm3d(out_channel,affine=True)\n",
    "\n",
    "\n",
    "    def forward(self,x, res1 = None, res2 = None, res3 = None):\n",
    "\n",
    "        x1_out = self.conv(x,res1,res2,res3)\n",
    "        x2_out = self.w(x,res1,res2,res3)\n",
    "        x_out = x1_out + x2_out\n",
    "        if self.normalize:\n",
    "            x_out = self.normalize_layer(x_out)\n",
    "        if self.non_lin:\n",
    "            x_out = F.gelu(x_out)\n",
    "        return x_out\n",
    "\n",
    "#######\n",
    "## New 3D Neural operator\n",
    "## Without any domain extension of the input function\n",
    "## Following neural operator is desinged for predicting next 40 time steps from the input (Initial 10 time steps).\n",
    "########\n",
    "class Uno3D(nn.Module):\n",
    "    def __init__(self, in_width, width,pad = 0, factor = 1, pad_both = False):\n",
    "        super(Uno3D, self).__init__()\n",
    "\n",
    "        self.in_width = in_width # input channel\n",
    "        self.width = width \n",
    "        \n",
    "        self.padding = pad  # pad the domain if input is non-periodic\n",
    "        self.pad_both = pad_both\n",
    "        self.fc_n1 = nn.Linear(self.in_width, self.width//2)\n",
    "\n",
    "        self.fc0 = nn.Linear(self.width//2, self.width) # input channel is 3: (a(x, y), x, y)\n",
    "        \n",
    "        self.conv0 = OperatorBlock_3D(self.width, 2*factor*self.width, 48, 48, 96, 24, 24, 24)\n",
    "        \n",
    "        self.conv1 = OperatorBlock_3D(2*factor*self.width, 4*factor*self.width, 32, 32, 64, 16, 16, 16)\n",
    "        \n",
    "        self.conv2 = OperatorBlock_3D(4*factor*self.width, 8*factor*self.width, 16, 16, 32, 8, 8, 8)\n",
    "        \n",
    "        self.conv3 = OperatorBlock_3D(8*factor*self.width, 16*factor*self.width, 8, 8, 16, 4, 4, 4)\n",
    "        \n",
    "        self.conv4 = OperatorBlock_3D(16*factor*self.width, 16*factor*self.width, 8, 8, 16, 4, 4, 4)\n",
    "        \n",
    "        self.conv5 = OperatorBlock_3D(16*factor*self.width, 8*factor*self.width, 16, 16, 32, 4, 4, 4) \n",
    "        \n",
    "        self.conv6 = OperatorBlock_3D(8*factor*self.width, 4*factor*self.width, 32, 32, 64, 8, 8, 8)\n",
    "        \n",
    "        self.conv7 = OperatorBlock_3D(8*factor*self.width, 2*factor*self.width, 48, 48, 96, 16, 16, 16)\n",
    "        \n",
    "        self.conv8 = OperatorBlock_3D(4*factor*self.width, 2*self.width, 64, 64, 128, 24, 24, 32) # will be reshaped\n",
    "\n",
    "        self.fc1 = nn.Linear(3*self.width, 4*self.width)\n",
    "        self.fc2 = nn.Linear(4*self.width, 2)\n",
    "        \n",
    "        #self.bn_fc_1 = torch.nn.BatchNorm3d(self.width)\n",
    "        #self.bn_fc0 = torch.nn.InstanceNorm3d(self.width)\n",
    "        #self.bn_fc1 = torch.nn.InstanceNorm3d(4*self.width)\n",
    "\n",
    "    def forward(self, x, time_grid = 128):\n",
    "        grid = self.get_grid(x.shape, x.device)\n",
    "        x = torch.cat((x, grid), dim=-1)\n",
    "        x_fc = self.fc_n1(x)\n",
    "        x_fc = F.gelu(x_fc)\n",
    "        x_fc0 = self.fc0(x_fc)\n",
    "        x_fc0 = F.gelu(x_fc0)\n",
    "        \n",
    "        x_fc0 = x_fc0.permute(0, 4, 1, 2, 3)\n",
    "        \n",
    "        #x_fc0 = F.pad(x_fc0, [0,self.padding,0,0,0,0],mode ='constant')\n",
    "        \n",
    "        D1,D2,D3 = x_fc0.shape[-3],x_fc0.shape[-2],x_fc0.shape[-1]\n",
    "\n",
    "        x_c0 = self.conv0(x_fc0)\n",
    "        x_c1 = self.conv1(x_c0)\n",
    "        x_c2 = self.conv2(x_c1)\n",
    "        \n",
    "        x_c3 = self.conv3(x_c2)\n",
    "        x_c4 = self.conv4(x_c3)\n",
    "        x_c5 = self.conv5(x_c4)\n",
    "        \n",
    "        x_c6 = self.conv6(x_c5)\n",
    "        x_c6 = torch.cat([x_c6, torch.nn.functional.interpolate(x_c1, size = (x_c6.shape[2], x_c6.shape[3],x_c6.shape[4]),mode = 'trilinear',align_corners=True)], dim=1)\n",
    "        \n",
    "        x_c7 = self.conv7(x_c6)\n",
    "        x_c7 = torch.cat([x_c7, torch.nn.functional.interpolate(x_c0, size = (x_c7.shape[2], x_c7.shape[3],x_c7.shape[4]),mode = 'trilinear',align_corners=True)], dim=1)\n",
    "        \n",
    "        x_c8 = self.conv8(x_c7,D1,D2,time_grid+self.padding)\n",
    "\n",
    "        x_c8 = torch.cat([x_c8,torch.nn.functional.interpolate(x_fc0, size = (x_c8.shape[2], x_c8.shape[3],x_c8.shape[4]),mode = 'trilinear',align_corners=True)], dim=1)\n",
    "        \n",
    "        if self.padding!=0:\n",
    "            if self.pad_both:\n",
    "                x_c8 = x_c8[...,self.padding//2:-self.padding//2]\n",
    "            else:\n",
    "                x_c8 = x_c8[...,:-self.padding]\n",
    "\n",
    "        x_c8 = x_c8.permute(0, 2, 3, 4, 1)\n",
    "\n",
    "        x_fc1 = self.fc1(x_c8)\n",
    "        #x_fc1 = self.bn_fc1(x_fc1.permute(0, 4, 1, 2, 3)).permute(0, 2, 3, 4, 1)\n",
    "        x_fc1 = F.gelu(x_fc1)\n",
    "        x_out = self.fc2(x_fc1)\n",
    "        \n",
    "        return x_out\n",
    "    \n",
    "    def get_grid(self, shape, device):\n",
    "        batchsize, size_x, size_y, size_z = shape[0], shape[1], shape[2], shape[3]\n",
    "        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n",
    "        gridx = gridx.reshape(1, size_x, 1, 1, 1).repeat([batchsize, 1, size_y, size_z, 1])\n",
    "        gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n",
    "        gridy = gridy.reshape(1, 1, size_y, 1, 1).repeat([batchsize, size_x, 1, size_z, 1])\n",
    "        gridz = torch.tensor(np.linspace(0, 1, size_z), dtype=torch.float)\n",
    "        gridz = gridz.reshape(1, 1, 1, size_z, 1).repeat([batchsize, size_x, size_y, 1, 1])\n",
    "        return torch.cat((gridx, gridy, gridz), dim=-1).to(device)\n",
    "\n",
    "def count_params(model):\n",
    "    c = 0\n",
    "    for p in list(model.parameters()):\n",
    "        c += reduce(operator.mul,\n",
    "                    list(p.size() + (2,) if p.is_complex() else p.size()))\n",
    "    return c\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "501e3b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building training set\n",
      "Building test set\n",
      "torch.Size([8, 64, 64, 128, 3])\n",
      "torch.Size([8, 64, 64, 128, 2])\n",
      "preprocessing finished, time used: 4.160167830064893\n",
      "694319914\n"
     ]
    }
   ],
   "source": [
    "################################################################\n",
    "# configs\n",
    "################################################################\n",
    "\n",
    "sub = 4\n",
    "npad = 0\n",
    "S = 64 - 2 * npad\n",
    "T_in = 1\n",
    "T = 128 - 2 * npad\n",
    "T_max = 400\n",
    "nx, ny = 64, 64\n",
    "\n",
    "ntrain = 8\n",
    "ntest = 2\n",
    "width = 16\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "in_channels = 3\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "runtime = np.zeros(2, )\n",
    "t1 = default_timer()\n",
    "\n",
    "################################################################\n",
    "# load data\n",
    "################################################################\n",
    "datapath = './'\n",
    "Vsset = torch.tensor(np.load(datapath + 'model/Vs.npy')).float()\n",
    "Vpset = torch.tensor(np.load(datapath + 'model/Vp.npy')).float()\n",
    "srcxy = torch.tensor(np.load(datapath + 'model/srcxy.npy'), dtype=torch.int)\n",
    "srct = np.zeros(T_max)\n",
    "tmp = np.load(datapath + 'model/srct.npy')[0]\n",
    "srct[:tmp.size] = tmp\n",
    "srct = torch.tensor(srct, dtype=torch.float)\n",
    "Vpset = F.interpolate(Vpset.view(-1, 1, nx, ny),\n",
    "                      size=(S, S), antialias=True, mode='bilinear')\n",
    "\n",
    "Vsset = F.interpolate(Vsset.view(-1, 1, nx, ny),\n",
    "                      size=(S, S), antialias=True, mode='bilinear')\n",
    "\n",
    "\n",
    "train_a = torch.zeros((ntrain, S, S, T, in_channels))\n",
    "train_u = torch.zeros((ntrain, S, S, T, 2))\n",
    "\n",
    "test_a = torch.zeros((ntest, S, S, T, in_channels))\n",
    "test_u = torch.zeros((ntest, S, S, T, 2))\n",
    "\n",
    "x = torch.arange(nx)\n",
    "y = torch.arange(ny)\n",
    "xx, yy = torch.meshgrid(x, y, indexing=\"ij\")\n",
    "src_width = 2\n",
    "\n",
    "offset_train = 0\n",
    "print(\"Building training set\")\n",
    "for i in range(ntrain):\n",
    "    u_wf = torch.tensor(np.load(datapath +\n",
    "                                'waveform/No' +\n",
    "                                str(offset_train +\n",
    "                                    i) +\n",
    "                                '.npy')).float().permute(3, 0, 1, 2).view(1, 2, nx, ny, -\n",
    "                                                                          1)\n",
    "    u_wf = F.interpolate(u_wf, size=(S, S, T), mode='trilinear').view(\n",
    "        2, S, S, -1).permute(1, 2, 3, 0)\n",
    "    train_a[i, :, :, :, 0] = Vpset[offset_train + i, :, :].view(S, S, 1)\n",
    "    train_a[i, :, :, :, 1] = Vsset[offset_train + i, :, :].view(S, S, 1)\n",
    "\n",
    "    t_start = 0\n",
    "    t_stop = t_start + T\n",
    "    train_u[i] = u_wf[:, :, t_start:t_stop, :]\n",
    "    spatial_func = torch.exp(-(xx - srcxy[offset_train + i, 0]) ** 2 / src_width ** 2) *         torch.exp(-(yy - srcxy[offset_train + i, 1]) ** 2 / src_width ** 2)\n",
    "    spatial_func = F.interpolate(\n",
    "        spatial_func.view(\n",
    "            1, 1, nx, ny), size=(\n",
    "            S, S), antialias=True, mode='bilinear')\n",
    "    train_a[i, :, :, :, 2] = spatial_func.view(\n",
    "        S, S, 1) * torch.abs(F.interpolate(srct.view(1,1,-1), size=( T), mode='linear'))\n",
    "\n",
    "offset_test = ntrain\n",
    "print(\"Building test set\")\n",
    "for i in range(ntest):\n",
    "    u_wf = torch.tensor(np.load(datapath +\n",
    "                                'waveform/No' +\n",
    "                                str(offset_test +\n",
    "                                    i) +\n",
    "                                '.npy')).float().permute(3, 0, 1, 2).view(1, 2, nx, ny, -\n",
    "                                                                          1)\n",
    "    u_wf = F.interpolate(u_wf, size=(S, S, T), mode='trilinear').view(\n",
    "        2, S, S, -1).permute(1, 2, 3, 0)\n",
    "    test_a[i, :, :, :, 0] = Vpset[offset_test + i, :, :].view(S, S, 1)\n",
    "    test_a[i, :, :, :, 1] = Vsset[offset_test + i, :, :].view(S, S, 1)\n",
    "\n",
    "    t_start = 0\n",
    "    t_stop = t_start + T\n",
    "    test_u[i] = u_wf[:, :, t_start:t_stop, :]\n",
    "    spatial_func = torch.exp(-(xx - srcxy[offset_test + i, 0]) ** 2 / src_width ** 2) *         torch.exp(-(yy - srcxy[offset_test + i, 1]) ** 2 / src_width ** 2)\n",
    "    spatial_func = F.interpolate(\n",
    "        spatial_func.view(\n",
    "            1, 1, nx, ny), size=(\n",
    "            S, S), antialias=True, mode='bilinear')\n",
    "    test_a[i, :, :, :, 2] = spatial_func.view(\n",
    "        S, S, 1) * torch.abs(F.interpolate(srct.view(1,1,-1), size=( T), mode='linear'))\n",
    "\n",
    "print(train_a.shape)\n",
    "print(train_u.shape)\n",
    "\n",
    "a_normalizer = InputNormalizer(train_a)\n",
    "y_normalizer = InputNormalizer(train_u)\n",
    "a_normalizer.cuda()\n",
    "y_normalizer.cuda()\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(\n",
    "        train_a,\n",
    "        train_u),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(\n",
    "        test_a,\n",
    "        test_u),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)\n",
    "\n",
    "t2 = default_timer()\n",
    "\n",
    "print('preprocessing finished, time used:', t2 - t1)\n",
    "\n",
    "\n",
    "out, x, y = [], [], []\n",
    "\n",
    "model = Uno3D(in_channels + 3, width, pad=0).to(device)\n",
    "\n",
    "#model = UNO_3D(in_channels + 3, width, S, T, pad=npad).to(device)\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    "    weight_decay=1e-5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(count_params(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9be95926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.314715189859271 1.0706849098205566 1.038224458694458 1.0367131233215332 1.0158281326293945 1.0744596719741821 1.0407129526138306\n",
      "1 1.2898991331458092 1.045721411705017 1.0225578546524048 1.0208604335784912 1.007822036743164 1.0484837293624878 1.0241951942443848\n",
      "2 1.2622177228331566 1.0262469053268433 1.010532021522522 1.0094645023345947 1.0030450820922852 1.0281116962432861 1.0113639831542969\n",
      "3 1.284719342365861 1.0117501020431519 1.0023083686828613 1.0026497840881348 1.0013346672058105 1.0127612352371216 1.0024166107177734\n",
      "4 1.2741169054061174 1.0020146369934082 0.9983502626419067 1.0001165866851807 1.001772403717041 1.0022255182266235 0.9979700446128845\n",
      "5 1.2686746697872877 0.9969125986099243 0.9947887659072876 1.0005877017974854 1.002645492553711 0.9965042471885681 0.9939157962799072\n",
      "6 1.2686995174735785 0.991974413394928 0.9906934499740601 1.0015556812286377 1.0029761791229248 0.9909098148345947 0.9893287420272827\n",
      "7 1.2669328823685646 0.986285924911499 0.986458420753479 1.0016382932662964 1.0026686191558838 0.9845801591873169 0.9846572875976562\n",
      "8 1.2728171590715647 0.9802975058555603 0.9828507900238037 1.000732421875 1.0020320415496826 0.9780269861221313 0.9807195663452148\n",
      "9 1.2699448633939028 0.9748278856277466 0.9810162782669067 0.9993382096290588 1.0014220476150513 0.972104549407959 0.9787490367889404\n",
      "10 1.2549129035323858 0.971260666847229 0.9807260036468506 0.9979950785636902 1.0011074542999268 0.9682902097702026 0.9784613847732544\n",
      "11 1.2711983937770128 0.9693129062652588 0.9819127917289734 0.9970644116401672 1.00118887424469 0.9662294387817383 0.9797710180282593\n",
      "12 1.3145795967429876 0.9689755439758301 0.9832888245582581 0.9966943264007568 1.0014824867248535 0.9658956527709961 0.9812673330307007\n",
      "13 1.4059025719761848 0.9690596461296082 0.9841119050979614 0.9966609477996826 1.001747488975525 0.96599280834198 0.9821524620056152\n",
      "14 1.263844145461917 0.9687241911888123 0.9843125343322754 0.9966381192207336 1.0018701553344727 0.9656226634979248 0.9823617339134216\n",
      "15 1.264447769150138 0.9677708148956299 0.9838452339172363 0.9964451193809509 1.0018410682678223 0.9645847678184509 0.9818457365036011\n",
      "16 1.2738945968449116 0.9660431146621704 0.9828214049339294 0.9960371255874634 1.0017027854919434 0.962710440158844 0.98072350025177\n",
      "17 1.2919739224016666 0.9636889100074768 0.9815734624862671 0.9954655170440674 1.0015382766723633 0.9601582288742065 0.9793552160263062\n",
      "18 1.2849002592265606 0.9611170291900635 0.980474054813385 0.9948538541793823 1.0014368295669556 0.9573684930801392 0.9781448841094971\n",
      "19 1.2658906523138285 0.958794355392456 0.9798426628112793 0.9943411350250244 1.0014615058898926 0.9548447132110596 0.977440595626831\n",
      "20 1.2681832127273083 0.9571317434310913 0.9800711870193481 0.9940270185470581 1.0016180276870728 0.9530322551727295 0.9776771068572998\n",
      "21 1.262816995382309 0.9566001296043396 0.9806311726570129 0.993923544883728 1.0018140077590942 0.952453076839447 0.9782775640487671\n",
      "22 1.256692212074995 0.9564054012298584 0.9810435175895691 0.9938864707946777 1.0019569396972656 0.9522408246994019 0.9787198305130005\n",
      "23 1.265826229006052 0.9560072422027588 0.9811978936195374 0.9937772154808044 1.0020129680633545 0.9518105983734131 0.9788851141929626\n",
      "24 1.300274221226573 0.955260157585144 0.9811039566993713 0.9935383200645447 1.0019967555999756 0.9510070085525513 0.9787825345993042\n",
      "25 1.267661515623331 0.9541350603103638 0.9808810949325562 0.9931792616844177 1.001950740814209 0.9497968554496765 0.9785400629043579\n",
      "26 1.257567984983325 0.9527328610420227 0.9807529449462891 0.9927525520324707 1.0019280910491943 0.9482862949371338 0.9784002304077148\n",
      "27 1.2628249060362577 0.9513176083564758 0.9810915589332581 0.9923346042633057 1.0019762516021729 0.9467601776123047 0.9787710905075073\n",
      "28 1.2726003788411617 0.9503803253173828 0.9818705320358276 0.9919986724853516 1.0020840167999268 0.9457560777664185 0.9796246290206909\n",
      "29 1.2639808785170317 0.9500225782394409 0.982602059841156 0.991746187210083 1.0021960735321045 0.9453866481781006 0.9804250001907349\n",
      "30 1.2620250433683395 0.9496071338653564 0.9831526875495911 0.9915001392364502 1.0022938251495361 0.9449523687362671 0.9810259342193604\n",
      "31 1.2604992371052504 0.9489787817001343 0.98349928855896 0.991227388381958 1.002394199371338 0.9442844986915588 0.9813998937606812\n",
      "32 1.282231718301773 0.9481240510940552 0.9836880564689636 0.9909377098083496 1.0025150775909424 0.9433670043945312 0.9815962314605713\n",
      "33 1.3103108908981085 0.9470904469490051 0.9839500188827515 0.9906445741653442 1.0026689767837524 0.9422510862350464 0.981870174407959\n",
      "34 1.264443550258875 0.9461625814437866 0.9844491481781006 0.9903658628463745 1.0028488636016846 0.9412511587142944 0.9824047684669495\n",
      "35 1.261302787810564 0.9455404877662659 0.9849722385406494 0.990100622177124 1.0030152797698975 0.940589427947998 0.9829674959182739\n",
      "36 1.264179788529873 0.9449469447135925 0.9854505062103271 0.9898143410682678 1.0031490325927734 0.9399616718292236 0.9834840297698975\n",
      "37 1.268188750371337 0.9442441463470459 0.9859000444412231 0.9894865155220032 1.0032607316970825 0.939217209815979 0.983971118927002\n",
      "38 1.2615800108760595 0.9433821439743042 0.9863881468772888 0.9891197681427002 1.0033752918243408 0.9383001923561096 0.9845007658004761\n",
      "39 1.2627050299197435 0.9424172639846802 0.987078070640564 0.9887322187423706 1.003509759902954 0.937271237373352 0.9852523803710938\n",
      "40 1.2638459131121635 0.9415733218193054 0.9878935813903809 0.9883372187614441 1.0036447048187256 0.9363773465156555 0.9861435294151306\n",
      "41 1.263918425887823 0.940869152545929 0.9885730147361755 0.9879226684570312 1.0037519931793213 0.9356409907341003 0.9868865013122559\n",
      "42 1.2834608349949121 0.9400414824485779 0.9890087246894836 0.9874701499938965 1.0038257837295532 0.9347716569900513 0.9873624444007874\n",
      "43 1.2927512228488922 0.9389656186103821 0.9893344640731812 0.9869757890701294 1.0038793087005615 0.933631181716919 0.987718403339386\n",
      "44 1.2576147094368935 0.937777042388916 0.9898002743721008 0.9864425659179688 1.0039349794387817 0.9323697686195374 0.9882298111915588\n",
      "45 1.2587475944310427 0.9366601705551147 0.9904119968414307 0.9858582615852356 1.0040099620819092 0.9311937093734741 0.9889011383056641\n",
      "46 1.257301177829504 0.9354721307754517 0.9911249279975891 0.9851707220077515 1.0040698051452637 0.9299501180648804 0.9896866083145142\n",
      "47 1.2612988390028477 0.9340326189994812 0.9918373227119446 0.9843326210975647 1.0040359497070312 0.9284437894821167 0.9904819130897522\n",
      "48 1.2615998834371567 0.9324119687080383 0.9928033351898193 0.9834689497947693 1.004110336303711 0.926738977432251 0.9915469884872437\n",
      "49 1.2624047305434942 0.9308358430862427 0.9934350252151489 0.982421875 1.0040602684020996 0.9251041412353516 0.9922544360160828\n",
      "50 1.2645753845572472 0.9294492602348328 0.9955503940582275 0.9816820621490479 1.0044491291046143 0.9236456751823425 0.9945616722106934\n",
      "51 1.2660557124763727 0.9287146925926208 0.9955751895904541 0.9802454113960266 1.0043611526489258 0.9229890704154968 0.9945990443229675\n",
      "52 1.2610544450581074 0.9255571961402893 0.9967411756515503 0.9793167114257812 1.0044682025909424 0.9195839166641235 0.9958826303482056\n",
      "53 1.2632387895137072 0.923728883266449 0.9985846877098083 0.9782795906066895 1.0048060417175293 0.9176676869392395 0.9978934526443481\n",
      "54 1.2616280317306519 0.9206017851829529 1.0002129077911377 0.9760816693305969 1.0050020217895508 0.9144374132156372 0.9996808767318726\n",
      "55 1.2636251039803028 0.9182581901550293 1.0011839866638184 0.9742748737335205 1.0049352645874023 0.9120341539382935 1.0007672309875488\n",
      "56 1.2646460700780153 0.9147610664367676 1.0028975009918213 0.9726337194442749 1.0050760507583618 0.9083307981491089 1.0026555061340332\n",
      "57 1.2649039402604103 0.9116075038909912 1.0053993463516235 0.9705938100814819 1.0053802728652954 0.9050534963607788 1.0054014921188354\n",
      "58 1.2598541136831045 0.907912015914917 1.0076793432235718 0.9675043821334839 1.0055108070373535 0.9012906551361084 1.007920265197754\n",
      "59 1.2662790920585394 0.9035497307777405 1.0103449821472168 0.9647819995880127 1.0058343410491943 0.8967461585998535 1.0108461380004883\n",
      "60 1.2626473233103752 0.8995614647865295 1.0132232904434204 0.9621135592460632 1.0060967206954956 0.8926112651824951 1.0140150785446167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 1.2781321071088314 0.8941566944122314 1.0158065557479858 0.9577260613441467 1.0063345432281494 0.8870934247970581 1.0168590545654297\n",
      "62 1.2945908978581429 0.8891575336456299 1.0190646648406982 0.9542859196662903 1.0065827369689941 0.8819210529327393 1.020451545715332\n",
      "63 1.2589241284877062 0.8828964829444885 1.023069977760315 0.9496189951896667 1.0071232318878174 0.8754829168319702 1.0248419046401978\n",
      "64 1.2613478247076273 0.8767493367195129 1.0268070697784424 0.9443910717964172 1.0075404644012451 0.8692336082458496 1.0289478302001953\n",
      "65 1.2607248164713383 0.870589554309845 1.0320067405700684 0.9406582117080688 1.0087101459503174 0.8628041744232178 1.034595251083374\n",
      "66 1.2522711344063282 0.8634965419769287 1.0352818965911865 0.9335472583770752 1.0089163780212402 0.8557131886482239 1.038211464881897\n",
      "67 1.260466292500496 0.8561655879020691 1.0419206619262695 0.928678572177887 1.0103424787521362 0.8481086492538452 1.0454293489456177\n",
      "68 1.2570740878582 0.8482930660247803 1.0452603101730347 0.9215721487998962 1.0104782581329346 0.8401509523391724 1.0491249561309814\n",
      "69 1.257371561601758 0.8383013606071472 1.0500727891921997 0.9142125844955444 1.0115447044372559 0.8298668265342712 1.0543537139892578\n",
      "70 1.2541287653148174 0.829926609992981 1.056821346282959 0.9066352248191833 1.0132557153701782 0.821403443813324 1.061661958694458\n",
      "71 1.2580628246068954 0.8206254243850708 1.0596539974212646 0.8986899852752686 1.0132925510406494 0.8119515776634216 1.064805269241333\n",
      "72 1.2740196231752634 0.8112669587135315 1.0674728155136108 0.8918971419334412 1.0153404474258423 0.8023080825805664 1.0732653141021729\n",
      "73 1.2930101919919252 0.8008818030357361 1.0708117485046387 0.8806741833686829 1.0154213905334473 0.7920160293579102 1.0769662857055664\n",
      "74 1.2619787491858006 0.7887137532234192 1.0764415264129639 0.8722530603408813 1.0165488719940186 0.7794316411018372 1.0830962657928467\n",
      "75 1.2579090055078268 0.7776641249656677 1.0822560787200928 0.8625133037567139 1.017890453338623 0.7682364583015442 1.0894079208374023\n",
      "76 1.2650663051754236 0.7652820348739624 1.0855071544647217 0.8505772352218628 1.0181241035461426 0.7558047771453857 1.092994213104248\n",
      "77 1.2583758924156427 0.7533164620399475 1.0942612886428833 0.8405051231384277 1.0204850435256958 0.7436287999153137 1.1024587154388428\n",
      "78 1.2620797827839851 0.7416625618934631 1.0956872701644897 0.8284051418304443 1.0200653076171875 0.7320245504379272 1.1040897369384766\n",
      "79 1.2610051110386848 0.7290924787521362 1.1057604551315308 0.8179673552513123 1.0239835977554321 0.7192175388336182 1.1148468255996704\n",
      "80 1.260074744001031 0.7157207727432251 1.1071803569793701 0.8040311932563782 1.0231945514678955 0.7059085369110107 1.1165120601654053\n",
      "81 1.2612646389752626 0.6985954642295837 1.1139487028121948 0.7917460203170776 1.0250158309936523 0.688245415687561 1.1238300800323486\n",
      "82 1.2686222288757563 0.684925377368927 1.1220792531967163 0.7780240178108215 1.0286364555358887 0.6745810508728027 1.1324617862701416\n",
      "83 1.2669234033674002 0.6715078353881836 1.1226991415023804 0.7645223140716553 1.0279452800750732 0.6611728668212891 1.1332273483276367\n",
      "84 1.2606297507882118 0.6559655666351318 1.1345372200012207 0.7527815699577332 1.0319724082946777 0.6452082395553589 1.1459333896636963\n",
      "85 1.2712330650538206 0.6396398544311523 1.137547254562378 0.7358649373054504 1.0332763195037842 0.6289481520652771 1.1491329669952393\n",
      "86 1.2824255842715502 0.6225623488426208 1.1396429538726807 0.7222877740859985 1.0337843894958496 0.6114817261695862 1.1514050960540771\n",
      "87 1.2692296169698238 0.608009397983551 1.1523191928863525 0.7090767025947571 1.038602352142334 0.5967797636985779 1.164954423904419\n",
      "88 1.2894354164600372 0.5939299464225769 1.1510151624679565 0.6930789947509766 1.0373159646987915 0.5829133987426758 1.1636483669281006\n",
      "89 1.2600846365094185 0.5762513279914856 1.1582093238830566 0.6801043748855591 1.041078805923462 0.5647121071815491 1.1712238788604736\n",
      "90 1.2597254365682602 0.5595957040786743 1.1648317575454712 0.6637328863143921 1.042863130569458 0.5480248928070068 1.1783838272094727\n",
      "91 1.2587879840284586 0.5425633788108826 1.1668986082077026 0.6480008959770203 1.0430068969726562 0.5308480858802795 1.180664300918579\n",
      "92 1.260660657659173 0.5268067717552185 1.173453450202942 0.6347984671592712 1.0466878414154053 0.5148077011108398 1.1875386238098145\n",
      "93 1.2647519707679749 0.5118480920791626 1.175033688545227 0.618876039981842 1.0459699630737305 0.4999561309814453 1.1893742084503174\n",
      "94 1.261645097285509 0.49826690554618835 1.185181736946106 0.6058613061904907 1.0511736869812012 0.48631200194358826 1.2000715732574463\n",
      "95 1.2657284457236528 0.484569251537323 1.1821212768554688 0.590691864490509 1.048364281654358 0.4727778732776642 1.1969830989837646\n",
      "96 1.262241691350937 0.46878504753112793 1.190624713897705 0.5787913799285889 1.053173303604126 0.4565621316432953 1.2058970928192139\n",
      "97 1.269435316324234 0.4547351598739624 1.1941592693328857 0.5616316795349121 1.0538274049758911 0.4428578019142151 1.2097516059875488\n",
      "98 1.277382805943489 0.4380343556404114 1.1927459239959717 0.5483218431472778 1.052936315536499 0.42578020691871643 1.208280324935913\n",
      "99 1.2946274057030678 0.426445871591568 1.2036621570587158 0.5366035103797913 1.0586482286453247 0.4142061173915863 1.2197747230529785\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    L2 = LpLoss(p=2, size_average=False)\n",
    "    L1 = LpLoss(p=1, size_average=False)\n",
    "    # y_normalizer.cuda()\n",
    "    losstrain = np.zeros(epochs)\n",
    "    losstest = np.zeros(epochs)\n",
    "    l2train = np.zeros(epochs)\n",
    "    l2test = np.zeros(epochs)\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        t1 = default_timer()\n",
    "        train_loss = 0\n",
    "        train_L2 = 0.0\n",
    "        train_L1 = 0.0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            y = y_normalizer.encode(y)\n",
    "            x = a_normalizer.encode(x)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x)\n",
    "\n",
    "            L2_loss = L2(out.view(x.shape[0], -1), y.view(x.shape[0], -1))\n",
    "            L1_loss = L1(out.view(x.shape[0], -1), y.view(x.shape[0], -1))\n",
    "            loss = 0.9 * L1_loss + 0.1 * L2_loss\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                train_loss += loss.item()\n",
    "                train_L2 += L2_loss.item()\n",
    "                train_L1 += L1_loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        test_L1 = 0.0\n",
    "        test_L2 = 0.0\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                y = y_normalizer.encode(y)\n",
    "                x = a_normalizer.encode(x)\n",
    "                out = model(x)\n",
    "\n",
    "                L2_loss = L2(out.view(x.shape[0], -1), y.view(x.shape[0], -1))\n",
    "                L1_loss = L1(out.view(x.shape[0], -1), y.view(x.shape[0], -1))\n",
    "                loss = 0.9 * L1_loss + 0.1 * L2_loss\n",
    "                test_loss += loss.item()\n",
    "                test_L2 += L2_loss.item()\n",
    "                test_L1 += L1_loss.item()\n",
    "\n",
    "        train_loss /= ntrain\n",
    "        test_loss /= ntest\n",
    "        train_L1 /= ntrain\n",
    "        train_L2 /= ntrain\n",
    "        test_L1 /= ntest\n",
    "        test_L2 /= ntest\n",
    "\n",
    "        t2 = default_timer()\n",
    "        print(\n",
    "            ep,\n",
    "            t2 - t1,\n",
    "            train_loss,\n",
    "            test_loss,\n",
    "            train_L2,\n",
    "            test_L2,\n",
    "            train_L1,\n",
    "            test_L1)\n",
    "\n",
    "        eps = 1e-3\n",
    "        losstrain[ep] = train_loss\n",
    "        losstest[ep] = test_loss\n",
    "        l2train[ep] = train_L2\n",
    "        l2test[ep] = test_L2\n",
    "    return losstrain, losstest\n",
    "\n",
    "losstrain, losstest = train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1de4ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:seis37] *",
   "language": "python",
   "name": "conda-env-seis37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
